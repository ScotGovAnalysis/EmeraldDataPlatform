{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "from itertools import product\n",
    "\n",
    "def px_escape(text):\n",
    "    \"\"\"Escape quotes in strings for PX format.\"\"\"\n",
    "    if isinstance(text, str):\n",
    "        return text.replace('\"', '\"\"')\n",
    "    return text\n",
    "\n",
    "def tidy_to_pxstat(\n",
    "    input_file,\n",
    "    output_file=None,\n",
    "    stub_cols=None,\n",
    "    heading_cols=None,\n",
    "    title=None,\n",
    "    subject_area=None,\n",
    "    matrix_code=None,\n",
    "    decimals=None,\n",
    "    value_col=\"Value\",\n",
    "    source=\"Scottish Government\",\n",
    "    agg_method=\"mean\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Convert Tidy format CSV to monolingual PxStat format.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    input_file : str\n",
    "        Path to input CSV file.\n",
    "    output_file : str, optional\n",
    "        Path to output PX file (default: input_name + \".px\").\n",
    "    stub_cols : list, optional\n",
    "        Columns to use as stub dimensions (rows).\n",
    "    heading_cols : list, optional\n",
    "        Columns to use as heading dimensions (columns).\n",
    "    title : str, optional\n",
    "        Title for the PX dataset.\n",
    "    subject_area : str, optional\n",
    "        Subject area for the dataset.\n",
    "    matrix_code : str, optional\n",
    "        Matrix code for the dataset.\n",
    "    decimals : int, optional\n",
    "        Number of decimals to use.\n",
    "    value_col : str, optional\n",
    "        Column name containing the values (default: \"Value\").\n",
    "    source : str, optional\n",
    "        Data source (default: \"National Records of Scotland\").\n",
    "    agg_method : str, optional\n",
    "        Aggregation method for duplicates (\"sum\" or \"mean\", default: \"mean\").\n",
    "    \"\"\"\n",
    "    print(f\"Loading data from {input_file}...\")\n",
    "    try:\n",
    "        # Load the CSV\n",
    "        df = pd.read_csv(input_file)\n",
    "\n",
    "        # Validate required columns\n",
    "        required_cols = [value_col]\n",
    "        if not all(col in df.columns for col in required_cols):\n",
    "            raise ValueError(f\"Missing required column: {value_col}\")\n",
    "\n",
    "        # Auto-detect dimensions if not specified\n",
    "        if stub_cols is None and heading_cols is None:\n",
    "            all_dims = [col for col in df.columns if col not in [value_col, \"Measurement\", \"Units\", \"FeatureName\", \"FeatureType\"]]\n",
    "            stub_cols = [\"DateCode\"] if \"DateCode\" in all_dims else all_dims[:1]\n",
    "            heading_cols = [\n",
    "                col for col in all_dims if col not in stub_cols and len(df[col].dropna().unique()) > 1\n",
    "            ]\n",
    "        elif stub_cols is None:\n",
    "            stub_cols = [col for col in df.columns if col not in [value_col, \"Measurement\", \"Units\", \"FeatureName\", \"FeatureType\"] + (heading_cols or [])]\n",
    "        elif heading_cols is None:\n",
    "            heading_cols = [col for col in df.columns if col not in [value_col, \"Measurement\", \"Units\", \"FeatureName\", \"FeatureType\"] + (stub_cols or [])]\n",
    "\n",
    "        print(f\"Stub dimensions: {stub_cols}\")\n",
    "        print(f\"Heading dimensions: {heading_cols}\")\n",
    "\n",
    "        # Simplify to needed columns\n",
    "        group_cols = stub_cols + heading_cols\n",
    "        if not group_cols:\n",
    "            raise ValueError(\"No valid dimension columns specified or detected.\")\n",
    "        df_simple = df[group_cols + [value_col]].copy()\n",
    "\n",
    "        # Make values numeric\n",
    "        df_simple[value_col] = pd.to_numeric(df_simple[value_col], errors=\"coerce\")\n",
    "\n",
    "        # Fix duplicates by grouping\n",
    "        df_simple = df_simple.groupby(group_cols, as_index=False).agg({value_col: agg_method})\n",
    "\n",
    "        # Create all combinations of dimensions\n",
    "        dim_vals = {col: sorted(df_simple[col].dropna().unique()) for col in group_cols}\n",
    "        full_index = pd.MultiIndex.from_product(\n",
    "            [dim_vals[col] for col in group_cols],\n",
    "            names=group_cols\n",
    "        )\n",
    "\n",
    "        # Reindex to ensure all combinations\n",
    "        indexed_df = df_simple.set_index(group_cols).reindex(full_index)\n",
    "\n",
    "        # Generate data values\n",
    "        data_values = [\n",
    "            '\"..\"' if pd.isna(v) else str(round(v, decimals or 3))\n",
    "            for v in indexed_df[value_col]\n",
    "        ]\n",
    "\n",
    "        # Metadata\n",
    "        creation_date = datetime.today().strftime(\"%Y%m%d %H:%M\")\n",
    "        if title is None:\n",
    "            title = f\"Data from {os.path.basename(input_file)}\"\n",
    "        if subject_area is None:\n",
    "            subject_area = \"Statistics\"\n",
    "        if matrix_code is None:\n",
    "            matrix_code = re.sub(r'[^A-Z0-9]', '', os.path.basename(input_file).upper()) or \"DATA1\"\n",
    "        if decimals is None:\n",
    "            max_decimals = max(\n",
    "                [len(str(x).split('.')[-1]) if '.' in str(x) else 0 for x in df_simple[value_col].dropna()]\n",
    "            ) if not df_simple[value_col].dropna().empty else 0\n",
    "            decimals = min(max_decimals, 6)\n",
    "\n",
    "        units = px_escape(df['Units'].iloc[0] if 'Units' in df.columns and not df['Units'].empty else 'Count')\n",
    "        header = f\"\"\"CHARSET=\"UTF-16\";\n",
    "AXIS-VERSION=\"2013\";\n",
    "CREATION-DATE=\"{creation_date}\";\n",
    "MATRIX=\"{matrix_code}\";\n",
    "DECIMALS={decimals};\n",
    "SUBJECT-AREA=\"{px_escape(subject_area)}\";\n",
    "SUBJECT-CODE=\"{matrix_code[:4] if len(matrix_code) >= 4 else matrix_code}\";\n",
    "CONTENTS=\"{px_escape(title)}\";\n",
    "TITLE=\"{px_escape(title)} - by {', '.join(group_cols)}\";\n",
    "UNITS=\"{units}\";\n",
    "STUB=\"{','.join(f'\"{px_escape(col)}\"' for col in stub_cols)}\";\n",
    "HEADING=\"{','.join(f'\"{px_escape(col)}\"' for col in heading_cols)}\";\n",
    "SOURCE=\"{px_escape(source)}\";\n",
    "\"\"\"\n",
    "\n",
    "        # VALUES and CODES blocks\n",
    "        def px_values_and_codes(name, values):\n",
    "            quoted_vals = \",\".join(f'\"{px_escape(str(v))}\"' for v in values)\n",
    "            quoted_codes = \",\".join(f'\"{i+1:02d}\"' for i in range(len(values)))\n",
    "            return f'VALUES(\"{name}\")={quoted_vals};\\nCODES(\"{name}\")={quoted_codes};\\n'\n",
    "\n",
    "        meta_parts = \"\".join(px_values_and_codes(col, dim_vals[col]) for col in group_cols)\n",
    "\n",
    "        # Make output filename\n",
    "        if output_file is None:\n",
    "            output_file = os.path.splitext(input_file)[0] + \".px\"\n",
    "\n",
    "        # Write to file\n",
    "        print(f\"Writing {len(data_values)} data points to {output_file}...\")\n",
    "        with open(output_file, \"w\", encoding=\"utf-16\") as f:\n",
    "            f.write(header)\n",
    "            f.write(meta_parts)\n",
    "            f.write(\"DATA=\\n\")\n",
    "            f.write(\" \".join(data_values) + \"\\n\")\n",
    "            f.write(\";\")\n",
    "\n",
    "        print(f\"✅ PX file saved as: {output_file}\")\n",
    "        return output_file\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing file: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 2: Call the function\n",
    "tidy_to_pxstat(\n",
    "    input_file=\"gross-domestic-product-quarterly-output-by-industry.csv\",\n",
    "    output_file=\"gross-domestic-product-quarterly-output-by-industry.px\",\n",
    "    stub_cols=[\"DateCode\", \"Industry Sector (SIC 07)\", \"Measurement\"],\n",
    "    heading_cols=[\"FeatureCode\"],\n",
    "    title=\"Police Officer Quarterly Strength\",\n",
    "    subject_area=\"Public Safety\",\n",
    "    matrix_code=\"POLICE01\",\n",
    "    decimals=3,\n",
    "    agg_method=\"mean\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
