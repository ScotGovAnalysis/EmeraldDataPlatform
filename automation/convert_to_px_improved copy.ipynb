{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97df4f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running conversion with the following configuration:\n",
      "input_file: Fire - Type of Incident.csv\n",
      "output_file: Fire - Type of Incident.px\n",
      "value_col: Value\n",
      "stub_cols: ['DateCode']\n",
      "heading_cols: ['FeatureCode', 'Accident Status', 'Type of Fire']\n",
      "title: Fire - Type of Incident\n",
      "subject_area: Incidents\n",
      "matrix_code: SCOJQYF\n",
      "decimals: 0\n",
      "source: Scottish Fire and Rescue Service\n",
      "agg_method: sum\n",
      "Loading data from Fire - Type of Incident.csv...\n",
      "Expected data points: 130368\n",
      "Writing 130368 data points to Fire - Type of Incident.px...\n",
      "✅ PX file saved as: Fire - Type of Incident.px\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import string\n",
    "import random\n",
    "import itertools\n",
    "import uuid\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "def generate_matrix_code() -> str:\n",
    "    \"\"\"Generate a matrix code starting with 'SCO' followed by 4 random uppercase letters.\"\"\"\n",
    "    return \"SCO\" + ''.join(random.choice(string.ascii_uppercase) for _ in range(4))\n",
    "\n",
    "def px_escape(text: str) -> str:\n",
    "    \"\"\"Escape quotes in strings for PX format.\"\"\"\n",
    "    if isinstance(text, str):\n",
    "        return text.replace('\"', '\"\"')\n",
    "    return str(text)\n",
    "\n",
    "def define_dimensions() -> Dict[str, Dict[str, List[str]]]:\n",
    "    \"\"\"Define dimension values and codes based on provided documentation.\"\"\"\n",
    "    return {\n",
    "        \"DateCode\": {\n",
    "            \"values\": [\n",
    "                \"2009/2010\", \"2010/2011\", \"2011/2012\", \"2012/2013\", \"2013/2014\",\n",
    "                \"2014/2015\", \"2015/2016\", \"2016/2017\", \"2017/2018\", \"2018/2019\",\n",
    "                \"2019/2020\", \"20020/2021\", \"2021/2022\", \"2022/2023\"\n",
    "            ],\n",
    "            \"codes\": [f\"{i+1:02d}\" for i in range(14)]\n",
    "        },\n",
    "        \"Accident Status\": {\n",
    "            \"values\": [\"Accidental\", \"All\", \"Not Accidental\"],\n",
    "            \"codes\": [\"1\", \"2\", \"3\"]\n",
    "        },\n",
    "        \"Type of Fire\": {\n",
    "            \"values\": [\n",
    "                \"All\", \"Chimney Fire\", \"Dwelling Fire\", \"Other Building Fire\",\n",
    "                \"Other Primary Fire\", \"Outdoor Fire\", \"Refuse Fire\", \"Vehicle Fire\"\n",
    "            ],\n",
    "            \"codes\": [f\"{i+1}\" for i in range(8)]\n",
    "        }\n",
    "    }\n",
    "\n",
    "def tidy_to_pxstat(\n",
    "    input_file: str,\n",
    "    output_file: Optional[str] = None,\n",
    "    stub_cols: Optional[List[str]] = None,\n",
    "    heading_cols: Optional[List[str]] = None,\n",
    "    title: Optional[str] = None,\n",
    "    subject_area: Optional[str] = None,\n",
    "    matrix_code: Optional[str] = None,\n",
    "    decimals: Optional[int] = 0,\n",
    "    value_col: str = \"Value\",\n",
    "    source: str = \"Scottish Fire and Rescue Service\",\n",
    "    agg_method: str = \"sum\"\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Convert Tidy format CSV to monolingual PxStat format with complete matrix.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    input_file : str\n",
    "        Path to input CSV file.\n",
    "    output_file : str, optional\n",
    "        Path to output PX file (default: input_name + \".px\").\n",
    "    stub_cols : list, optional\n",
    "        Columns to use as stub dimensions (rows, default: [\"DateCode\"]).\n",
    "    heading_cols : list, optional\n",
    "        Columns to use as heading dimensions (columns, default: [\"FeatureCode\", \"Accident Status\", \"Type of Fire\"]).\n",
    "    title : str, optional\n",
    "        Title for the PX dataset.\n",
    "    subject_area : str, optional\n",
    "        Subject area for the dataset.\n",
    "    matrix_code : str, optional\n",
    "        Matrix code for the dataset (default: generated as SCO+4 random letters).\n",
    "    decimals : int, optional\n",
    "        Number of decimals to use (default: 0 for count data).\n",
    "    value_col : str, optional\n",
    "        Column name containing the values (default: \"Value\").\n",
    "    source : str, optional\n",
    "        Data source (default: \"Scottish Fire and Rescue Service\").\n",
    "    agg_method : str, optional\n",
    "        Aggregation method for duplicates (\"sum\" or \"mean\", default: \"sum\").\n",
    "    \"\"\"\n",
    "    print(f\"Loading data from {input_file}...\")\n",
    "    try:\n",
    "        # Load CSV with optimized dtypes\n",
    "        df = pd.read_csv(input_file, low_memory=False, dtype_backend=\"numpy_nullable\")\n",
    "        \n",
    "        # Validate required columns\n",
    "        required_cols = [value_col] + (stub_cols or []) + (heading_cols or [])\n",
    "        missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "        if missing_cols:\n",
    "            raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "        \n",
    "        # Default dimensions\n",
    "        stub_cols = stub_cols or [\"DateCode\"]\n",
    "        heading_cols = heading_cols or [\"FeatureCode\", \"Accident Status\", \"Type of Fire\"]\n",
    "        group_cols = stub_cols + heading_cols\n",
    "        \n",
    "        # Convert categorical columns to 'category' dtype\n",
    "        for col in group_cols:\n",
    "            if col in df.columns:\n",
    "                df[col] = df[col].astype(str).astype('category')\n",
    "        \n",
    "        # Simplify to needed columns\n",
    "        df_simple = df[group_cols + [value_col]].copy()\n",
    "        \n",
    "        # Make values numeric\n",
    "        df_simple[value_col] = pd.to_numeric(df_simple[value_col], errors=\"coerce\")\n",
    "        if df_simple[value_col].isna().any():\n",
    "            print(f\"Warning: {df_simple[value_col].isna().sum()} non-numeric values in {value_col} set to NaN.\")\n",
    "        \n",
    "        # Aggregate duplicates\n",
    "        df_agg = df_simple.groupby(group_cols, as_index=False, observed=True).agg({value_col: agg_method})\n",
    "        \n",
    "        # Define dimensions\n",
    "        dimensions = define_dimensions()\n",
    "        feature_codes = sorted(df[\"FeatureCode\"].dropna().unique())\n",
    "        dimensions[\"FeatureCode\"] = {\n",
    "            \"values\": feature_codes,\n",
    "            \"codes\": [f\"{i+1:03d}\" for i in range(len(feature_codes))]\n",
    "        }\n",
    "        \n",
    "        # Generate all possible combinations\n",
    "        dim_values = [dimensions[col][\"values\"] for col in group_cols]\n",
    "        all_combinations = list(itertools.product(*dim_values))\n",
    "        expected_count = len(all_combinations)\n",
    "        print(f\"Expected data points: {expected_count}\")\n",
    "        \n",
    "        # Create a mapping from data\n",
    "        data_map = {\n",
    "            tuple(row[col] for col in group_cols): row[value_col]\n",
    "            for _, row in df_agg.iterrows()\n",
    "        }\n",
    "        \n",
    "        # Generate data values\n",
    "        data_values = []\n",
    "        for combo in all_combinations:\n",
    "            value = data_map.get(combo, pd.NA)\n",
    "            data_values.append(\"..\" if pd.isna(value) else str(int(value) if decimals == 0 else round(value, decimals)))\n",
    "        \n",
    "        # Verify data count\n",
    "        actual_count = len(data_values)\n",
    "        if actual_count != expected_count:\n",
    "            raise ValueError(f\"Data count mismatch: expected {expected_count}, got {actual_count}\")\n",
    "        \n",
    "        # Metadata\n",
    "        creation_date = datetime.now().strftime(\"%Y%m%d %H:%M\")\n",
    "        title = title or f\"Fire Incidents from {os.path.basename(input_file)}\"\n",
    "        subject_area = subject_area or \"Incidents\"\n",
    "        matrix_code = matrix_code or generate_matrix_code()\n",
    "        units = px_escape(df[\"Units\"].iloc[0] if \"Units\" in df.columns and not df[\"Units\"].isna().all() else \"Fires\")\n",
    "        \n",
    "        header = f\"\"\"CHARSET=\"UTF-16\";\n",
    "AXIS-VERSION=\"2013\";\n",
    "CREATION-DATE=\"{creation_date}\";\n",
    "MATRIX=\"{matrix_code}\";\n",
    "DECIMALS={decimals};\n",
    "SUBJECT-AREA=\"{px_escape(subject_area)}\";\n",
    "SUBJECT-CODE=\"{matrix_code[:4] if len(matrix_code) >= 4 else matrix_code}\";\n",
    "CONTENTS=\"{px_escape(title)}\";\n",
    "TITLE=\"{px_escape(title)} - by {', '.join(px_escape(col) for col in group_cols)}\";\n",
    "UNITS=\"{units}\";\n",
    "STUB=\"{','.join(f'\"{px_escape(col)}\"' for col in stub_cols)}\";\n",
    "HEADING=\"{','.join(f'\"{px_escape(col)}\"' for col in heading_cols)}\";\n",
    "SOURCE=\"{px_escape(source)}\";\n",
    "\"\"\"\n",
    "        \n",
    "        # VALUES and CODES blocks\n",
    "        def px_values_and_codes(name: str, dim: Dict) -> str:\n",
    "            quoted_vals = \",\".join(f'\"{px_escape(str(v))}\"' for v in dim[\"values\"])\n",
    "            quoted_codes = \",\".join(f'\"{px_escape(str(c))}\"' for c in dim[\"codes\"])\n",
    "            return f'VALUES(\"{name}\")={quoted_vals};\\nCODES(\"{name}\")={quoted_codes};\\n'\n",
    "        \n",
    "        meta_parts = \"\".join(px_values_and_codes(col, dimensions[col]) for col in group_cols)\n",
    "        \n",
    "        # Output filename\n",
    "        output_file = output_file or os.path.splitext(input_file)[0] + \".px\"\n",
    "        \n",
    "        # Write to file\n",
    "        print(f\"Writing {len(data_values)} data points to {output_file}...\")\n",
    "        with open(output_file, \"w\", encoding=\"utf-16\") as f:\n",
    "            f.write(header)\n",
    "            f.write(meta_parts)\n",
    "            f.write(\"DATA=\\n\")\n",
    "            # Write data in chunks to manage memory\n",
    "            chunk_size = 1000\n",
    "            for i in range(0, len(data_values), chunk_size):\n",
    "                f.write(\" \".join(data_values[i:i+chunk_size]) + \"\\n\")\n",
    "            f.write(\";\")\n",
    "        \n",
    "        print(f\"✅ PX file saved as: {output_file}\")\n",
    "        return output_file\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing file: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuration\n",
    "    CONFIG = {\n",
    "        \"input_file\": \"Fire - Type of Incident.csv\",\n",
    "        \"output_file\": \"Fire - Type of Incident.px\",\n",
    "        \"value_col\": \"Value\",\n",
    "        \"stub_cols\": [\"DateCode\"],\n",
    "        \"heading_cols\": [\"FeatureCode\", \"Accident Status\", \"Type of Fire\"],\n",
    "        \"title\": \"Fire - Type of Incident\",\n",
    "        \"subject_area\": \"Incidents\",\n",
    "        \"matrix_code\": generate_matrix_code(),\n",
    "        \"decimals\": 0,  # Count data, no decimals\n",
    "        \"source\": \"Scottish Fire and Rescue Service\",\n",
    "        \"agg_method\": \"sum\"\n",
    "    }\n",
    "    \n",
    "    # Run conversion\n",
    "    print(\"Running conversion with the following configuration:\")\n",
    "    for key, value in CONFIG.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    tidy_to_pxstat(**CONFIG)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
